{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXd0TzkoyTMi"
   },
   "source": [
    "## Overview \n",
    "\n",
    "In this notebook we created a model with neural networks to estimate how much a caa would be worth if it had 7 rooms, taking into account the following information\n",
    "\n",
    "Imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "- How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1598111585747,
     "user": {
      "displayName": "Jhon Freddy Moofarry Villaquiran",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1JGr4J7kUl6BujdwadEwiNQhQvhbMg8QWPEn5NA=s64",
      "userId": "10620199596948843247"
     },
     "user_tz": 300
    },
    "id": "cckuf5nf0eHW",
    "outputId": "1610b10c-cb45-442b-9cf2-4c86bb757dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTSr4oTOyOaE"
   },
   "outputs": [],
   "source": [
    "\n",
    "def house_model(y_new):\n",
    "    xs = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0], dtype=float)\n",
    "    ys = np.array([100.0, 150.0, 200.0, 250.0, 300.0, 350.0, 450.0, 500.0, 550.0,600.0, 650.0,700.0], dtype=float)\n",
    "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "    model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "    model.fit(xs,ys,epochs=100)\n",
    "    return (model.predict(y_new)[0]+1) //100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1598111618422,
     "user": {
      "displayName": "Jhon Freddy Moofarry Villaquiran",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1JGr4J7kUl6BujdwadEwiNQhQvhbMg8QWPEn5NA=s64",
      "userId": "10620199596948843247"
     },
     "user_tz": 300
    },
    "id": "FcDM73g50gNr",
    "outputId": "113c958a-5d71-436e-ce03-53b2eec2a6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/sample - loss: 198488.6719\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 18117.3047\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 84us/sample - loss: 2024.5365\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 109us/sample - loss: 585.2718\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 131us/sample - loss: 453.1187\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 136us/sample - loss: 437.5934\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 131us/sample - loss: 432.5065\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 116us/sample - loss: 428.3853\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 120us/sample - loss: 424.3843\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 113us/sample - loss: 420.4279\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 119us/sample - loss: 416.5092\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 134us/sample - loss: 412.6266\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 244us/sample - loss: 408.7804\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 148us/sample - loss: 404.9704\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 98us/sample - loss: 401.1955\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 99us/sample - loss: 397.4556\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 110us/sample - loss: 393.7508\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 103us/sample - loss: 390.0807\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 94us/sample - loss: 386.4446\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 126us/sample - loss: 382.8427\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 226us/sample - loss: 379.2740\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 127us/sample - loss: 375.7389\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 102us/sample - loss: 372.2368\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 98us/sample - loss: 368.7670\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 121us/sample - loss: 365.3297\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 102us/sample - loss: 361.9244\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 105us/sample - loss: 358.5508\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 114us/sample - loss: 355.2087\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 186us/sample - loss: 351.8978\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 112us/sample - loss: 348.6176\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 113us/sample - loss: 345.3680\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 107us/sample - loss: 342.1489\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 338.9597\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 96us/sample - loss: 335.8003\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 94us/sample - loss: 332.6702\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 91us/sample - loss: 329.5691\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 90us/sample - loss: 326.4973\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 94us/sample - loss: 323.4541\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 155us/sample - loss: 320.4392\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 111us/sample - loss: 317.4522\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 119us/sample - loss: 314.4932\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 124us/sample - loss: 311.5619\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 117us/sample - loss: 308.6575\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 140us/sample - loss: 305.7805\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 111us/sample - loss: 302.9305\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 132us/sample - loss: 300.1068\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 257us/sample - loss: 297.3095\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 108us/sample - loss: 294.5384\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 82us/sample - loss: 291.7927\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 128us/sample - loss: 289.0728\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 286.3784\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 156us/sample - loss: 283.7091\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 116us/sample - loss: 281.0647\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 103us/sample - loss: 278.4448\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 96us/sample - loss: 275.8494\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 128us/sample - loss: 273.2779\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 270.7308\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 109us/sample - loss: 268.2072\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 141us/sample - loss: 265.7072\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 90us/sample - loss: 263.2304\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 93us/sample - loss: 260.7773\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 96us/sample - loss: 258.3464\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 100us/sample - loss: 255.9382\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 94us/sample - loss: 253.5527\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 98us/sample - loss: 251.1892\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 96us/sample - loss: 248.8477\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 96us/sample - loss: 246.5284\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 91us/sample - loss: 244.2302\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 98us/sample - loss: 241.9540\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 239.6986\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 88us/sample - loss: 237.4645\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 143us/sample - loss: 235.2511\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 146us/sample - loss: 233.0582\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 118us/sample - loss: 230.8855\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 125us/sample - loss: 228.7336\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 117us/sample - loss: 226.6014\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 99us/sample - loss: 224.4893\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 117us/sample - loss: 222.3969\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 185us/sample - loss: 220.3241\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 182us/sample - loss: 218.2701\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 108us/sample - loss: 216.2357\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 92us/sample - loss: 214.2200\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 107us/sample - loss: 212.2233\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 90us/sample - loss: 210.2450\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 95us/sample - loss: 208.2855\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 88us/sample - loss: 206.3439\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 126us/sample - loss: 204.4205\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 126us/sample - loss: 202.5151\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 91us/sample - loss: 200.6276\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 111us/sample - loss: 198.7574\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 117us/sample - loss: 196.9050\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 115us/sample - loss: 195.0694\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 127us/sample - loss: 193.2510\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 135us/sample - loss: 191.4498\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 95us/sample - loss: 189.6653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 100us/sample - loss: 187.8974\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 125us/sample - loss: 186.1460\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 110us/sample - loss: 184.4109\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 105us/sample - loss: 182.6921\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 94us/sample - loss: 180.9893\n",
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction = house_model([7.0])\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUxCbnQKp0Z8dYvpTwNWrL",
   "collapsed_sections": [],
   "name": "House_Prices_dl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
